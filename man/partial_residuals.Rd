% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/residuals.R
\name{partial_residuals}
\alias{partial_residuals}
\title{Augment a model fit with partial residuals for all terms}
\usage{
partial_residuals(fit)
}
\arguments{
\item{fit}{The model to obtain residuals for. This can be a model fit with
\code{lm()} or \code{glm()}, or any model whose \code{residuals()} method supports a \code{type = "partial"} argument that returns a matrix or data frame of partial
residuals.}
}
\value{
Data frame containing the model data and residuals in tidy form.
There is one row \emph{per predictor} per observation, with the following
columns:

\item{obs}{Row number of this observation in the original model data frame.}
\item{predictor_name}{Name of the predictor this row gives the partial
residual for.}
\item{predictor_value}{Value of the predictor this row gives the partial
residual for.}
\item{partial_resid}{Partial residual for this predictor for this
observation.}
\item{fitted}{Fitted value (on the response scale) for this observation,
obtained using \code{fitted()}.}
\item{linear_predictor}{Linear predictor for this observation, obtained using
\code{predict()}. For linear models, the fitted values and linear predictor are
identical.}
}
\description{
Construct a data frame containing the model data, partial residuals, fitted
values, and linear predictor, for use in residual diagnostic plots and other
analyses. The result is in tidy form (one row per predictor per observation),
allowing it to be easily manipulated for plots and simulations.
}
\details{
Consider a generalized linear model setting. We define \eqn{\mathbb{E}[Y \mid
X] = \mu(X)}{E[Y | X] = \mu(X)}. Let \eqn{g} be the link function relating
\eqn{\mu(X)} to the linear predictors, so \eqn{g(\mu(X)) = \beta^T X}. We
define the partial residual for covariate \eqn{j} to be

\deqn{(Y - \hat \mu) g'(\hat \mu) + \hat \beta^T X_j}

where \eqn{g'(\hat \mu)} is the first derivative of the link function with
respect to \eqn{\mu}, and \eqn{\hat \mu} gives the predictions from our
fitted model.

For example, in a linear model, \eqn{g'(\hat \mu) = 1}, so the partial
residuals for covariate \eqn{j} are the ordinary residuals plus the
contribution of \eqn{X_j} to the model fit. Since \eqn{\hat \mu} is also a
linear combination of the predictors, this gives us the partial residual of
\eqn{Y} on every predictor \emph{except} \eqn{X_j}:

\deqn{Y - \sum_{k \neq j} \hat \beta_k X_k}

When plotted against \eqn{X_j}, we expect this to produce a line with slope
\eqn{\hat \beta_j}. If instead the scatterplot has a curve, this suggests the
relationship between \eqn{X_j} and \eqn{Y} is nonlinear.
}
\references{
R. Dennis Cook. "Exploring Partial Residual Plots",
\emph{Technometrics}, 35:4 (1993), 351-362.
\url{https://doi.org/10.1080/00401706.1993.10485350}

Cook, R. Dennis, and Croos-Dabrera, R.
"Partial Residual Plots in Generalized Linear Models." \emph{Journal of the
American Statistical Association} 93, no. 442 (1998): 730â€“39.
\url{https://doi.org/10.2307/2670123}

Fox, J., & Weisberg, S. (2018). "Visualizing Fit and Lack of Fit in Complex
Regression Models with Predictor Effect Plots and Partial Residuals." \emph{Journal
of Statistical Software}, 87(9). \url{https://doi.org/10.18637/jss.v087.i09}
}
\seealso{
\code{\link[=binned_residuals]{binned_residuals()}}
}
